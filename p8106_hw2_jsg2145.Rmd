---
title: "p8106_hw2_jsg2145"
author: "Jared Garfinkel"
date: "3/16/2020"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(viridis)
library(caret)
library(glmnet)
library(patchwork)
library(gam)
library(pdp)
library(mgcv)
knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
theme_set(theme_minimal() + theme(legend.position = "bottom"))
```

```{r}
collegedf = read_csv("./data/College.csv") %>% 
  janitor::clean_names() %>% 
  mutate(college = factor(college)) %>% 
  select(outstate, everything())

college.train = collegedf %>% 
  filter(college != "Columbia University")
```

```{r}
x.train = model.matrix(outstate ~ apps + accept + enroll + top10perc + top25perc + f_undergrad + p_undergrad + room_board + books + personal + ph_d + terminal + s_f_ratio + perc_alumni + expend + grad_rate, college.train)[,-1]

y.train = pull(college.train, outstate)

ctrl1 = trainControl(method = "cv", number = 5)
```

```{r pcr in caret, echo = FALSE}
college.pcr = train(x.train, y.train,
                    method = "pcr",
                    tuneLength = 16,
                    trControl = ctrl1,
                    preProc = c("center", "scale"))
```

```{r, echo = FALSE, results = "hide", include = FALSE}
ggplot(college.pcr, highlight = TRUE)
```

```{r lasso in glmnet, echo = FALSE, results = "hide", include = FALSE}
cv.lasso = cv.glmnet(x.train, y.train, 
                     type.measure = "mse", 
                     alpha = 1, 
                     lambda = exp(seq(2, 5, length = 100)))

plot(cv.lasso)
```

```{r ridge in glmnet, echo = FALSE, results = "hide", include = FALSE}
cv.ridge = cv.glmnet(x.train, y.train, 
                     type.measure = "mse", 
                     alpha = 0, 
                     lambda = exp(seq(3, 8, length = 100)))

plot(cv.ridge)
```


```{r lasso in caret, echo = FALSE, include = FALSE}
college.lasso = train(x.train, y.train,
                    method = "glmnet",
                    tuneGrid = expand.grid(alpha = 1, 
                                          lambda = exp(seq(2, 5, length = 100))),
                    trControl = ctrl1)
```

```{r ridge in caret, echo = FALSE, include = FALSE}
college.ridge = train(x.train, y.train,
                    method = "glmnet",
                    tuneGrid = expand.grid(alpha = 0, 
                                          lambda = exp(seq(3, 8, length = 100))),
                    trControl = ctrl1)
```

```{r, echo = FALSE, include = FALSE}
college.lm <- train(x.train, y.train,
                method = "lm",
                trControl = ctrl1)
```

```{r, results = "hide"}
p1 = college.train %>% 
  ggplot(aes(x = apps, y = outstate)) +
  geom_point()

p2 = college.train %>% 
  ggplot(aes(x = accept, y = outstate)) +
  geom_point()

p3 = college.train %>% 
  ggplot(aes(x = enroll, y = outstate)) +
  geom_point()

p4 = college.train %>% 
  ggplot(aes(x = top10perc, y = outstate)) +
  geom_point()

p5 = college.train %>% 
  ggplot(aes(x = top25perc, y = outstate)) +
  geom_point()

p6 = college.train %>% 
  ggplot(aes(x = f_undergrad, y = outstate)) +
  geom_point()

p7 = college.train %>% 
  ggplot(aes(x = p_undergrad, y = outstate)) +
  geom_point()

p8 = college.train %>% 
  ggplot(aes(x = room_board, y = outstate)) +
  geom_point()

p9 = college.train %>% 
  ggplot(aes(x = books, y = outstate)) +
  geom_point()

p16 = college.train %>% 
  ggplot(aes(x = ph_d, y = outstate)) +
  geom_point()

p10 = college.train %>% 
  ggplot(aes(x = personal, y = outstate)) +
  geom_point()

p11 = college.train %>% 
  ggplot(aes(x = terminal, y = outstate)) +
  geom_point()

p12 = college.train %>% 
  ggplot(aes(x = s_f_ratio, y = outstate)) +
  geom_point()

p13 = college.train %>% 
  ggplot(aes(x = perc_alumni, y = outstate)) +
  geom_point()

p14 = college.train %>% 
  ggplot(aes(x = grad_rate, y = outstate)) +
  geom_point()

p15 = college.train %>% 
  ggplot(aes(x = expend, y = outstate)) +
  geom_point() + 
  scale_x_continuous(breaks = c(0, 20000, 40000, 65000))
```
## Part a
```{r, fig.height = 12, fig.width = 8}
plots = list(p1, p2, p3, p4, p5, p6, p7, p8, p9, p10, p11, p12, p13, p14, p15, p16)

wrap_plots(plots, ncol = 4)
```
## Part b
```{r, fig.height = 12, fig.width = 8}
spline.term9 = smooth.spline(pull(college.train, terminal), pull(college.train, outstate), df = 9)
spline.term10 = smooth.spline(pull(college.train, terminal), pull(college.train, outstate), df = 10)
spline.term11 = smooth.spline(pull(college.train, terminal), pull(college.train, outstate), df = 11)
spline.term12 = smooth.spline(pull(college.train, terminal), pull(college.train, outstate), df = 12)
spline.term13 = smooth.spline(pull(college.train, terminal), pull(college.train, outstate), df = 13)
spline.termA = smooth.spline(pull(college.train, terminal), pull(college.train, outstate), cv = TRUE)
spline.termA$df


plot(college.train$terminal, college.train$outstate)
points(x.train, cex = .5, 
       col = "darkgrey")
lines(spline.term11, col = "red ", lwd = 2)
lines(spline.termA, col = "blue", lwd = 2)
lines(spline.term9, col = "green", lwd = 2)
lines(spline.term13, col = "yellow", lwd = 2)
legend("topright", legend = c("11 DF", "4.7 DF", "9 DF", "13 DF"),
       col = c("red", "blue", "green", "yellow"), lty = 1, lwd = 2, cex = .8)
```

This graph shows a smoothing spline using cross validation to choose degrees of freedom compared with various other degrees of freedom.

## Part c
```{r}
gam1 = gam(outstate ~ apps + accept + enroll + top10perc + top25perc + f_undergrad + p_undergrad + room_board + books + personal + ph_d + terminal + s_f_ratio + perc_alumni + expend + grad_rate, data = college.train)
```

```{r, fig.height = 12, fig.width = 8}
par(mfrow = c(4,4))
plot(gam1, pages=1,residuals=TRUE,all.terms=TRUE,shade=TRUE,shade.col=2)
```

The above graph shows a plot of the partial dependence of each predictor in relation to the tuition. 

```{r}
vis.gam(gam1, view = c("apps", "accept"),
        plot.type = "contour", color = "topo")
```

This plot shows a contour of the dependence of two predictors on each other.

```{r gam in caret}
set.seed(22)
college.gam = train(x.train, y.train,
                    method = "gam",
                    tuneGrid = data.frame(method = "GCV.Cp", 
                                         select = c(TRUE,FALSE)),
                    trControl = ctrl1)

college.gam$bestTune

college.gam$finalModel
```

## Part d

```{r MARS in caret}
mars_grid <- expand.grid(degree = 1:2, 
                         nprune = 2:16)

college.earth = train(x.train, y.train,
                       method = "earth", tuneGrid = mars_grid, trControl = ctrl1)

ggplot(college.earth)

partial(college.earth, pred.var = "expend", plot = TRUE, rug = TRUE)

college.earth$bestTune

coef(college.earth$finalModel) 
```

Using multivariate adaptive regression spline (MARS), a final model is -0.745*"expend" - 1.294*"room_board" - 21.71*"grad_rate" - 0.337*"f_undergrad" - 1.442*"f_undergrad" - 79.612*"perc_alumni" + 0.417*"apps" + 0.947*"personal" + 4.572*"enroll" - 1.922*"accept" + 0.745*"expend."

```{r results, fig.length = 12, fig.width = 8}
resamp <- resamples(list(earth = college.earth,
                         gam = college.gam))

summary(resamp)

bwplot(resamp, metric = "RMSE")
```
## Part e
```{r}
columbia = collegedf %>% 
  filter(college == "Columbia University")

pred.earth = predict(college.earth, newdata = columbia)

pred.gam = predict(gam1, newdata = columbia)
```

The MARS model predicts a tuition of `r round(pred.earth, digits = 0)` dollars and the GAM model predicts a tuition of `r pred.gam` dollars. Because the MARS model has a lower RMSE it is appropriate to accept this model and predict a tuition of `r round(pred.earth, digits = 0)` dollars.